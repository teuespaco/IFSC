{"cells":[{"cell_type":"markdown","metadata":{"id":"aHN_yyrpkpEA"},"source":["# Fine-tuning com Stable Diffusion\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wnTMyW41cC1E"},"source":["## Instalação e configuração"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65592,"status":"ok","timestamp":1697073831220,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"u1tYwZ30Bx4A","outputId":"2067330f-31dc-44a1-cd9e-1c0ebe781409"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n","!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n","%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n","%pip install -q -U --pre triton==2.0.0\n","%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers"]},{"cell_type":"markdown","metadata":{"id":"G0NV324ZcL9L"},"source":["## Carregamento do modelo\n"]},{"cell_type":"markdown","metadata":{"id":"_MmYKn7nWeXW"},"source":["> Temos de uso\n","\n","* https://huggingface.co/spaces/CompVis/stable-diffusion-license\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1697068469889,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"DV-j9xddJzFI"},"outputs":[],"source":["model_sd = \"runwayml/stable-diffusion-v1-5\"\n","output_dir = \"/content/stable_diffusion_weights/zwx\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1697068476577,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"Tss3LcQfKMQn","outputId":"3559abee-c1bb-48fe-e2bd-e3bdd99abb19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Diretório: /content/stable_diffusion_weights/zwx\n"]}],"source":["print(f\"Diretório: {output_dir}\")\n","!mkdir -p $output_dir"]},{"cell_type":"markdown","metadata":{"id":"qn5ILIyDJIcX"},"source":["## Treinamento\n","\n","Lembrando que para realizar o treinamento com o Dreambooth precisamos do seguinte:\n","1. identificador único\n","2. nome de classe\n","3. imagens do sujeito a ser inserido\n","\n","O primeiro já temos, fizemos na etapa anterior.\n","\n","Para nossa implementação, vamos pegar a imagem de um rosto como exemplo. O identificador único pode ser zwx e a classe é person.\n","\n","Precisamos construir o prompt da instância (instance prompt)\n","a photo of [identificador único] [nome da classe]\n","\n","e um prompt de classe (class prompt)\n","> a photo of [nome da classe]\n","\n","O prompt da instância nesse exemplo será:\n","> a photo of zwx person\n","\n","Como o sujeito é uma pessoa, o prompt da classe será\n","\n","> a photo of a person"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1697068496877,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"3SFIuBq2L81f"},"outputs":[],"source":["concepts_list = [\n","    {\n","        \"instance_prompt\": \"zwx\",\n","        \"class_prompt\": \"photo of a person\",\n","        \"instance_data_dir\": \"/content/data/zwx\",\n","        \"class_data_dir\": \"/content/data/person\"\n","    }\n","]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1697068513257,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"SHXJqevANE6o"},"outputs":[],"source":["import json\n","import os\n","import random\n","\n","for c in concepts_list:\n","  os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n","\n","with open(\"concepts_list.json\", \"w\") as f:\n","  json.dump(concepts_list, f, indent=4)"]},{"cell_type":"markdown","metadata":{"id":"kA2sTtTqxLNv"},"source":["**Fazer o upload das imagens de treinamento na pasta /data/zwx**"]},{"cell_type":"markdown","metadata":{"id":"bgnhlQvYRteP"},"source":["### Parâmetros"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1697068602904,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"ljRvhiHxO_y5","outputId":"fc196296-8362-43e7-84e2-dd02d9bd2b8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["16 192 1280 1e-06 128\n"]}],"source":["num_imgs = 16\n","num_class_images = num_imgs * 12\n","max_num_steps = num_imgs * 80\n","learning_rate = 1e-6 # 0.0000001\n","lr_warmup_steps = int(max_num_steps / 10)\n","print(num_imgs, num_class_images, max_num_steps, learning_rate, lr_warmup_steps)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1722353,"status":"ok","timestamp":1697070337752,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"n2E02it5Q4Qp","outputId":"83f7082a-8e55-46bb-8b6d-17814df8e9cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-11 23:57:04.897332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Downloading (…)lve/main/config.json: 100% 547/547 [00:00<00:00, 3.31MB/s]\n","Downloading (…)ch_model.safetensors: 100% 335M/335M [00:01<00:00, 312MB/s]\n","Downloading (…)p16/model_index.json: 100% 543/543 [00:00<00:00, 3.13MB/s]\n","safety_checker/model.safetensors not found\n","Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n","Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 16.3MB/s]\n","\n","Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 2.36MB/s]\n","Fetching 15 files:   7% 1/15 [00:00<00:10,  1.28it/s]\n","Downloading (…)cheduler_config.json: 100% 307/307 [00:00<00:00, 1.76MB/s]\n","\n","Downloading (…)_checker/config.json: 100% 4.70k/4.70k [00:00<00:00, 22.8MB/s]\n","\n","Downloading (…)_encoder/config.json: 100% 636/636 [00:00<00:00, 4.51MB/s]\n","\n","Downloading pytorch_model.bin:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n","\n","Downloading pytorch_model.bin:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 1.73MB/s]\n","\n","\n","\n","Downloading (…)cc2/unet/config.json: 100% 806/806 [00:00<00:00, 3.26MB/s]\n","\n","Downloading pytorch_model.bin:   9% 21.0M/246M [00:00<00:01, 164MB/s]\u001b[A\n","\n","\n","Downloading (…)9cc2/vae/config.json: 100% 609/609 [00:00<00:00, 2.97MB/s]\n","\n","\n","\n","Downloading (…)okenizer_config.json: 100% 822/822 [00:00<00:00, 3.67MB/s]\n","\n","\n","\n","Downloading (…)tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 21.5MB/s]\n","\n","\n","Downloading pytorch_model.bin:   2% 10.5M/608M [00:00<00:15, 38.9MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   1% 10.5M/1.72G [00:00<00:19, 88.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:   3% 21.0M/608M [00:00<00:10, 54.8MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  34% 83.9M/246M [00:00<00:00, 171MB/s]\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:   6% 10.5M/167M [00:00<00:01, 102MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   2% 31.5M/1.72G [00:00<00:16, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:   7% 41.9M/608M [00:00<00:07, 76.2MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  43% 105M/246M [00:00<00:00, 143MB/s] \u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   2% 41.9M/1.72G [00:00<00:17, 97.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  19% 31.5M/167M [00:00<00:01, 119MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   3% 52.4M/1.72G [00:00<00:20, 81.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:   9% 52.4M/608M [00:00<00:08, 67.4MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  51% 126M/246M [00:00<00:00, 124MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   4% 62.9M/1.72G [00:00<00:22, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  10% 62.9M/608M [00:01<00:09, 57.7MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  31% 52.4M/167M [00:00<00:01, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  60% 147M/246M [00:01<00:01, 92.4MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   4% 73.4M/1.72G [00:01<00:27, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  38% 62.9M/167M [00:00<00:01, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   5% 83.9M/1.72G [00:01<00:25, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  12% 73.4M/608M [00:01<00:11, 46.1MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  44% 73.4M/167M [00:01<00:01, 67.9MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  68% 168M/246M [00:01<00:00, 86.9MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   5% 94.4M/1.72G [00:01<00:25, 64.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  14% 83.9M/608M [00:01<00:10, 50.0MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  50% 83.9M/167M [00:01<00:01, 66.1MB/s]\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  72% 178M/246M [00:01<00:00, 78.8MB/s]\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   6% 105M/1.72G [00:01<00:25, 62.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  56% 94.4M/167M [00:01<00:01, 63.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  16% 94.4M/608M [00:01<00:10, 50.8MB/s]\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  77% 189M/246M [00:02<00:00, 62.5MB/s]\u001b[A\n","Downloading pytorch_model.bin:  85% 210M/246M [00:02<00:00, 82.6MB/s]\u001b[A\n","\n","Downloading pytorch_model.bin:  17% 105M/608M [00:02<00:11, 42.1MB/s] \u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   7% 115M/1.72G [00:01<00:36, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  63% 105M/167M [00:01<00:01, 46.9MB/s] \u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  19% 115M/608M [00:02<00:09, 51.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   7% 126M/1.72G [00:02<00:30, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin:  94% 231M/246M [00:02<00:00, 92.5MB/s]\u001b[A\n","\n","Downloading pytorch_model.bin:  21% 126M/608M [00:02<00:08, 55.9MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  75% 126M/167M [00:02<00:00, 55.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   8% 136M/1.72G [00:02<00:30, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  22% 136M/608M [00:02<00:07, 59.9MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  81% 136M/167M [00:02<00:00, 60.2MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 147M/1.72G [00:02<00:29, 53.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","Downloading pytorch_model.bin: 100% 246M/246M [00:02<00:00, 90.2MB/s]\n","\n","\n","Downloading pytorch_model.bin:  24% 147M/608M [00:02<00:07, 58.1MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin:  88% 147M/167M [00:02<00:00, 60.0MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:   9% 157M/1.72G [00:02<00:26, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  26% 157M/608M [00:02<00:07, 59.4MB/s]\u001b[A\u001b[A\n","\n","\n","Downloading (…)on_pytorch_model.bin: 100% 167M/167M [00:02<00:00, 74.7MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin: 100% 167M/167M [00:02<00:00, 64.5MB/s]\n","\n","\n","Downloading pytorch_model.bin:  28% 168M/608M [00:02<00:06, 64.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  12% 199M/1.72G [00:02<00:17, 85.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  31% 189M/608M [00:03<00:05, 81.0MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  13% 220M/1.72G [00:03<00:15, 95.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  34% 210M/608M [00:03<00:04, 95.8MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  14% 241M/1.72G [00:03<00:14, 105MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  38% 231M/608M [00:03<00:03, 105MB/s] \u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  15% 262M/1.72G [00:03<00:13, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  41% 252M/608M [00:03<00:03, 108MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  16% 283M/1.72G [00:03<00:12, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  45% 273M/608M [00:03<00:02, 115MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  18% 304M/1.72G [00:03<00:11, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  48% 294M/608M [00:04<00:02, 116MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  19% 325M/1.72G [00:03<00:11, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  52% 315M/608M [00:04<00:02, 120MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  20% 346M/1.72G [00:04<00:11, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  55% 336M/608M [00:04<00:02, 119MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  21% 367M/1.72G [00:04<00:11, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  59% 357M/608M [00:04<00:02, 123MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  23% 388M/1.72G [00:04<00:10, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  62% 377M/608M [00:04<00:01, 125MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  24% 409M/1.72G [00:04<00:10, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  66% 398M/608M [00:04<00:01, 125MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  25% 430M/1.72G [00:04<00:10, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  69% 419M/608M [00:05<00:01, 126MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  26% 451M/1.72G [00:04<00:10, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  72% 440M/608M [00:05<00:01, 124MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  27% 472M/1.72G [00:05<00:09, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  76% 461M/608M [00:05<00:01, 123MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  29% 493M/1.72G [00:05<00:09, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  79% 482M/608M [00:05<00:00, 127MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  30% 514M/1.72G [00:05<00:09, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  83% 503M/608M [00:05<00:00, 127MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  31% 535M/1.72G [00:05<00:09, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  86% 524M/608M [00:05<00:00, 129MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  32% 556M/1.72G [00:05<00:10, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  90% 545M/608M [00:06<00:00, 108MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  34% 577M/1.72G [00:06<00:11, 95.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  93% 566M/608M [00:06<00:00, 97.3MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  34% 587M/1.72G [00:06<00:12, 93.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  95% 577M/608M [00:06<00:00, 95.1MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  35% 598M/1.72G [00:06<00:12, 91.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin:  97% 587M/608M [00:06<00:00, 94.5MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  36% 619M/1.72G [00:06<00:10, 103MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","Downloading pytorch_model.bin: 100% 608M/608M [00:06<00:00, 96.2MB/s]\u001b[A\u001b[A\n","\n","\n","\n","Downloading pytorch_model.bin: 100% 608M/608M [00:06<00:00, 88.2MB/s]\n","Fetching 15 files:  27% 4/15 [00:07<00:22,  2.05s/it]\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  38% 650M/1.72G [00:06<00:09, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  40% 682M/1.72G [00:06<00:07, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  41% 713M/1.72G [00:07<00:06, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  43% 734M/1.72G [00:07<00:05, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  45% 765M/1.72G [00:07<00:05, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  46% 797M/1.72G [00:07<00:04, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  48% 828M/1.72G [00:07<00:04, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  50% 860M/1.72G [00:07<00:04, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  52% 891M/1.72G [00:07<00:03, 219MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  54% 923M/1.72G [00:08<00:03, 237MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  55% 954M/1.72G [00:08<00:03, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  57% 986M/1.72G [00:08<00:02, 246MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  59% 1.02G/1.72G [00:08<00:02, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  61% 1.05G/1.72G [00:08<00:02, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  63% 1.08G/1.72G [00:08<00:02, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  65% 1.11G/1.72G [00:08<00:02, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  66% 1.14G/1.72G [00:08<00:02, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  68% 1.17G/1.72G [00:08<00:02, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  70% 1.21G/1.72G [00:09<00:01, 259MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  72% 1.24G/1.72G [00:09<00:01, 262MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  74% 1.27G/1.72G [00:09<00:01, 260MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  76% 1.30G/1.72G [00:09<00:01, 259MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  77% 1.33G/1.72G [00:09<00:01, 255MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  79% 1.36G/1.72G [00:09<00:01, 260MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  81% 1.39G/1.72G [00:09<00:01, 252MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  83% 1.43G/1.72G [00:09<00:01, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  85% 1.46G/1.72G [00:10<00:01, 252MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  87% 1.49G/1.72G [00:10<00:00, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  88% 1.52G/1.72G [00:10<00:00, 260MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  90% 1.55G/1.72G [00:10<00:00, 256MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  92% 1.58G/1.72G [00:10<00:00, 250MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  94% 1.61G/1.72G [00:10<00:00, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  96% 1.65G/1.72G [00:10<00:00, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin:  98% 1.68G/1.72G [00:10<00:00, 269MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Downloading (…)on_pytorch_model.bin: 100% 1.72G/1.72G [00:11<00:00, 155MB/s]\n","Fetching 15 files: 100% 15/15 [00:12<00:00,  1.23it/s]\n","/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n","  warnings.warn(\n","You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","10/11/2023 23:57:33 - INFO - __main__ - Number of class images to sample: 192.\n","Generating class images: 100% 48/48 [10:24<00:00, 13.01s/it]\n","\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n","================================================================================\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-x5olvhxizwzh --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n","  warn(\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n","CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n","CUDA SETUP: Detected CUDA version 118\n","CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n","/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:203: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n","  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n","Downloading (…)cheduler_config.json: 100% 308/308 [00:00<00:00, 529kB/s]\n","Caching latents: 100% 192/192 [00:42<00:00,  4.50it/s]\n","10/12/2023 00:08:58 - INFO - __main__ - ***** Running training *****\n","10/12/2023 00:08:58 - INFO - __main__ -   Num examples = 192\n","10/12/2023 00:08:58 - INFO - __main__ -   Num batches each epoch = 192\n","10/12/2023 00:08:58 - INFO - __main__ -   Num Epochs = 7\n","10/12/2023 00:08:58 - INFO - __main__ -   Instantaneous batch size per device = 1\n","10/12/2023 00:08:58 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n","10/12/2023 00:08:58 - INFO - __main__ -   Gradient Accumulation steps = 1\n","10/12/2023 00:08:58 - INFO - __main__ -   Total optimization steps = 1280\n","Steps: 100% 1280/1280 [15:49<00:00,  1.37it/s, loss=0.265, lr=1e-6]safety_checker/model.safetensors not found\n","You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n","\n","Generating samples:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n","Generating samples:  25% 1/4 [00:05<00:15,  5.19s/it]\u001b[A\n","Generating samples:  50% 2/4 [00:08<00:08,  4.19s/it]\u001b[A\n","Generating samples:  75% 3/4 [00:12<00:03,  3.89s/it]\u001b[A\n","Generating samples: 100% 4/4 [00:15<00:00,  3.93s/it]\n","[*] Weights saved at /content/stable_diffusion_weights/zwx/1280\n","Steps: 100% 1280/1280 [16:35<00:00,  1.29it/s, loss=0.265, lr=1e-6]\n"]}],"source":["!python3 train_dreambooth.py \\\n","  --pretrained_model_name_or_path=$model_sd \\\n","  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n","  --output_dir=$output_dir \\\n","  --revision=\"fp16\" \\\n","  --with_prior_preservation --prior_loss_weight=1.0 \\\n","  --seed=777 \\\n","  --resolution=512 \\\n","  --train_batch_size=1 \\\n","  --train_text_encoder \\\n","  --mixed_precision=\"fp16\" \\\n","  --use_8bit_adam \\\n","  --gradient_accumulation_steps=1 \\\n","  --learning_rate=$learning_rate \\\n","  --lr_scheduler=\"constant\" \\\n","  --lr_warmup_steps=80 \\\n","  --num_class_images=$num_class_images \\\n","  --sample_batch_size=4 \\\n","  --max_train_steps=$max_num_steps \\\n","  --save_interval=10000 \\\n","  --save_sample_prompt=\"zwx\" \\\n","  --concepts_list=\"concepts_list.json\""]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1697070380552,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"7scQ7SEUX8TS","outputId":"9548f0f5-8e1c-4392-b8b6-e3244b641aef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Diretório com os pesos: /content/stable_diffusion_weights/zwx/1280\n"]}],"source":["from natsort import natsorted\n","from glob import glob\n","import os\n","\n","weights_dir = natsorted(glob(output_dir + os.sep + \"*\"))[-1]\n","print(f\"Diretório com os pesos: {weights_dir}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":504,"status":"ok","timestamp":1697070383564,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"3mP-7mBCYXFe"},"outputs":[],"source":["import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","def grid_img(imgs, rows=1, cols=3, scale=1):\n","  assert len(imgs) == rows * cols\n","\n","  w, h = imgs[0].size\n","  w, h = int(w*scale), int(h*scale)\n","\n","  grid = Image.new('RGB', size=(cols*w, rows*h))\n","  grid_w, grid_h = grid.size\n","\n","  for i, img in enumerate(imgs):\n","      img = img.resize((w,h), Image.LANCZOS)\n","      grid.paste(img, box=(i%cols*w, i//cols*h))\n","  return grid"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253,"output_embedded_package_id":"12j1c8F-j6p9rBWuWTpxfhcfc2k22fbK5"},"executionInfo":{"elapsed":3234,"status":"ok","timestamp":1697070391598,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"4Enfi1JtYcbV","outputId":"d151ddd2-96ee-45b4-da15-9d7b027c5eb4"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["weights_folder = output_dir\n","folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key = lambda x: int(x))\n","#print(folders)\n","\n","imgs_test = []\n","\n","for imgs, folder in enumerate(folders):\n","  #print(folder)\n","  folder_path = os.path.join(weights_folder, folder)\n","  image_folder = os.path.join(folder_path, \"samples\")\n","  images = [f for f in os.listdir(image_folder)]\n","\n","  for i in images:\n","    img_path = os.path.join(image_folder, i)\n","    r = Image.open(img_path)\n","    imgs_test.append(r)\n","\n","grid_img(imgs_test, rows=1, cols=4, scale=1)"]},{"cell_type":"markdown","metadata":{"id":"5V8wgU0HN-Kq"},"source":["## Converte os pesos para ckpt (checkpoint)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38895,"status":"ok","timestamp":1697071892179,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"8i62FUpbaAy3","outputId":"56f47131-fdfa-4681-abe5-64e9358bf576"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reshaping encoder.mid.attn_1.q.weight for SD format\n","Reshaping encoder.mid.attn_1.k.weight for SD format\n","Reshaping encoder.mid.attn_1.v.weight for SD format\n","Reshaping encoder.mid.attn_1.proj_out.weight for SD format\n","Reshaping decoder.mid.attn_1.q.weight for SD format\n","Reshaping decoder.mid.attn_1.k.weight for SD format\n","Reshaping decoder.mid.attn_1.v.weight for SD format\n","Reshaping decoder.mid.attn_1.proj_out.weight for SD format\n","Converted to ckpt and saved in /content/stable_diffusion_weights/zwx/1280/model.ckpt\n"]}],"source":["ckpt_path = weights_dir + \"/model.ckpt\"\n","\n","half_arg = \"--half\"\n","\n","!python convert_diffusers_to_original_stable_diffusion.py --model_path $weights_dir  --checkpoint_path $ckpt_path $half_arg\n","print(f\"Converted to ckpt and saved in {ckpt_path}\")"]},{"cell_type":"markdown","metadata":{"id":"ToNG4fd_dTbF"},"source":["## Inferência do modelo"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"hOPChokCgnYs","executionInfo":{"status":"ok","timestamp":1697071912283,"user_tz":180,"elapsed":12294,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"}}},"outputs":[],"source":["import torch\n","from torch import autocast\n","from diffusers import StableDiffusionPipeline, DDIMScheduler\n","from IPython.display import display"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1697071912286,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"bVQjAUalg0rR","outputId":"3d09dd95-ded3-4d52-9c06-49cec58ff071"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stable_diffusion_weights/zwx/1280\n"]}],"source":["model_path = weights_dir\n","print(model_path)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29322,"status":"ok","timestamp":1697071941597,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"pYH-k6_Rg9ER","outputId":"05df510c-39e5-4871-d1c5-00df410e4a39"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n","  warnings.warn(\n","You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"]}],"source":["pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to('cuda')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"iGVRuM2AhPDR","executionInfo":{"status":"ok","timestamp":1697071948008,"user_tz":180,"elapsed":267,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"}}},"outputs":[],"source":["pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n","pipe.enable_xformers_memory_efficient_attention()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"0IE9TmHaha-N","executionInfo":{"status":"ok","timestamp":1697071950172,"user_tz":180,"elapsed":282,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"}}},"outputs":[],"source":["seed = 777"]},{"cell_type":"markdown","metadata":{"id":"HsHKuCvbOQjR"},"source":["## Geração das imagens"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1rQ-LtKWfCDUf3VnyeIn3z3SS-lYn0AlF","referenced_widgets":["8f24c6b9e62f4149a8b5016488f8ac7f","ea13f831dec045cc82b744812b890ea7","5ff1f8ce3a4b4f59a199d4286a6068bb","1ff040bd4538419194fc1b47280fcffa","fb6cbd268f7847599bffb0476e38f30c","aca82f8dafdf494fa87bd5d6ff14e228","099364a9399c489195c99b544f38b961","ef0149cd451046eca27c1dac396eb60c","41b1217e2a074d72bf48142d7905a31b","b9125639ecbb4956993239c5fe722646","479bc2409dcc4b038d8a044fa7bd0881"]},"executionInfo":{"elapsed":27287,"status":"ok","timestamp":1697073647967,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"fA7X2A1uhk79","outputId":"d0ab8696-dc43-4c6f-f7bf-7f82ebfe7723"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["prompt = \"I request the creation of an image of a human face identified as 'zwx', with an emphasis on reality and well-balanced proportions. I look for natural facial features, such as expressive eyes with a visible pupil and iris, defined eyebrows, a nose and mouth in harmonious proportions. The skin must be represented with a natural texture, with realistic skin tones, including subtle nuances and shading.The face must be positioned frontally, with a symmetrical and neutral facial expression, without wrinkles or prominent expression marks. Image quality must be of a high standard, with high resolution, sharp details and realistic colors. Please avoid any distortions, excessive shadows or elements that make the face unrecognizable, such as facial deformities, disproportionate ears, oversized head and cheeks, crossed eyes, deformed hands or dark compositions. Make sure that the general anatomy of the face is that of a human being and that there are no elements that appear inappropriate or disproportionate, such as a forehead that is too wide, an excessively pronounced chin, or excessively thick lips. Please keep the image true to reality, avoiding any exaggerated features, caricatures or unnatural elements. This is a representation of an ordinary, authentic human face.\"\n","negative_prompt = \"Facial deformations (deformed eyes, closed gaze, distorted face), poor image quality, disproportionate ears, large head and cheeks, crossed eyes, deformed hands, obscure composition, inappropriate anatomy, disfigured appearance, poorly drawn face, poorly drawn hands, poorly drawn feet, blurry image, low resolution, out of frame, signature or watermark.\"\n","\n","num_samples = 5\n","guidance_scale = 7.5\n","num_inference_steps = 30\n","height = 512\n","width = 512\n","\n","seed = random.randint(0, 2147483647) # gera um valor aleatório\n","print(\"Seed: {}\".format(str(seed)))\n","generator = torch.Generator(device='cuda').manual_seed(seed)\n","\n","with autocast(\"cuda\"), torch.inference_mode():\n","    imgs = pipe(\n","        prompt,\n","        negative_prompt=negative_prompt,\n","        height=height, width=width,\n","        num_images_per_prompt=num_samples,\n","        num_inference_steps=num_inference_steps,\n","        guidance_scale=guidance_scale,\n","        generator=generator\n","    ).images\n","\n","for img in imgs:\n","    display(img)"]},{"cell_type":"markdown","metadata":{"id":"36RIClR0zUGI"},"source":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"k4DnF43q3nw1"}},{"cell_type":"markdown","metadata":{"id":"W0knos6McIMC"},"source":["### Mais exemplos de prompts\n","\n","* in the forest, in cairo, in cairo desert,  in a western scene, in star wars, in mountain fuji, in the snow, etc.\n","\n","> E combinações mais completas de prompt para você testar:\n","\n","* `photo of zwx person, closeup, mountain fuji in the background, natural lighting `\n","\n","* `digital painting of zwx in the snow, realistic, hd, vivid, sunset`\n","\n","* `watercolor painting of zwx person, realistic, blue and orange tones `\n","\n","* `digital painting of zwx person, hyperrealistic, fantasy, Surrealist, painted by Alphonse Mucha`\n","\n","* `painting of zwx person in star wars, realistic, 4k ultra hd, blue and red tones`\n","\n","* `photo of zwx person, in an armor, realistic, visible face, colored, detailed face, ultra detailed, natural lighting`\n","\n","* `photo of zwx person, cyberpunk, vivid, realistic, 4k ultra hd`\n","\n","* `anime painting of zwx person, chill day, by tim okamura, noah bradley, trending on artstation  `"]},{"cell_type":"markdown","metadata":{"id":"AnLH_bHghk1N"},"source":["### Testando vários prompts de uma vez"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e743b610b1ee4dc7b709542b45974f26","cf43151b067347bab730b016bb49aa49","2c8e3c6c9f5441c1a6bea4f0456fb5ed","5bea568795374220b2b42e19d8979dc5","5c9daeca32b9438badce79c8c3669514","9b0b3fc3d4aa4d2c96ac0f37fdff3f0e","6c23557d072a4ddfa30aa6c9bb734e8d","3491e282804a4a3a89a154c105254b32","0f87fa781b214a669e4cca37f25cd8b8","85ba286734af4b8e95d64d9ef9996957","80b4389599154ca2b12f03f930ee0158"],"output_embedded_package_id":"1XAN6NDcSt0ztVFNx6okIl2EGEzVMEna9"},"executionInfo":{"elapsed":23729,"status":"ok","timestamp":1697046295753,"user":{"displayName":"Ruan Binder","userId":"06382485365009247124"},"user_tz":180},"id":"kSwVF-HJi82_","outputId":"9067f5ba-07ca-418a-abc1-371b3718e021"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["prompt = [\"photo of zwx person, closeup, mountain fuji in the background, natural lighting\",\n","          \"photo of zwx person in the desert, closeup, pyramids in the background, natural lighting, frontal face\",\n","          \"photo of zwx person in the forest, natural lighting, frontal face\",\n","          \"photo of zwx person as an astronaut, natural lighting, frontal face, closeup, starry sky in the background\",\n","          \"face portrait of zwx in the snow, realistic, hd, vivid, sunset\"]\n","\n","negative_prompt = [\"bad anatomy, ugly, deformed, desfigured, distorted face, poorly drawn hands, poorly drawn face, poorly drawn feet, blurry, low quality, low definition, lowres, out of frame, out of image, cropped, cut off, signature, watermark\" ] * len(prompt)\n","num_samples = 1\n","guidance_scale = 7.5\n","num_inference_steps = 30\n","height = 512\n","width = 512\n","\n","seed = random.randint(0, 2147483647) # gera um valor aleatório\n","print(\"Seed: {}\".format(str(seed)))\n","generator = torch.Generator(device='cuda').manual_seed(seed)\n","\n","with autocast(\"cuda\"), torch.inference_mode():\n","    imgs = pipe(\n","        prompt,\n","        negative_prompt=negative_prompt,\n","        height=height, width=width,\n","        num_images_per_prompt=num_samples,\n","        num_inference_steps=num_inference_steps,\n","        guidance_scale=guidance_scale,\n","        generator=generator\n","    ).images\n","\n","for img in imgs:\n","    display(img)"]},{"cell_type":"markdown","metadata":{"id":"s0K6_4rqT4UY"},"source":["## Salvando os resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kkG_sFoLjarD"},"outputs":[],"source":["!mkdir resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D05rXsN9jeXp"},"outputs":[],"source":["for i, img in enumerate(imgs):\n","  img.save('resultados/resultado_{}.png'.format(i+1))"]},{"cell_type":"markdown","metadata":{"id":"-ioxxvHoicPs"},"source":["> Mais informações sobre essa implementação do Dreambooth:\n","https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1M4DLx9XhyvoJV_VxkSMrKtU2AVNgq9Rh","timestamp":1696457948948}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e743b610b1ee4dc7b709542b45974f26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf43151b067347bab730b016bb49aa49","IPY_MODEL_2c8e3c6c9f5441c1a6bea4f0456fb5ed","IPY_MODEL_5bea568795374220b2b42e19d8979dc5"],"layout":"IPY_MODEL_5c9daeca32b9438badce79c8c3669514"}},"cf43151b067347bab730b016bb49aa49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b0b3fc3d4aa4d2c96ac0f37fdff3f0e","placeholder":"​","style":"IPY_MODEL_6c23557d072a4ddfa30aa6c9bb734e8d","value":"100%"}},"2c8e3c6c9f5441c1a6bea4f0456fb5ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3491e282804a4a3a89a154c105254b32","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f87fa781b214a669e4cca37f25cd8b8","value":30}},"5bea568795374220b2b42e19d8979dc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85ba286734af4b8e95d64d9ef9996957","placeholder":"​","style":"IPY_MODEL_80b4389599154ca2b12f03f930ee0158","value":" 30/30 [00:20&lt;00:00,  1.48it/s]"}},"5c9daeca32b9438badce79c8c3669514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b0b3fc3d4aa4d2c96ac0f37fdff3f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c23557d072a4ddfa30aa6c9bb734e8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3491e282804a4a3a89a154c105254b32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f87fa781b214a669e4cca37f25cd8b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85ba286734af4b8e95d64d9ef9996957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b4389599154ca2b12f03f930ee0158":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f24c6b9e62f4149a8b5016488f8ac7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea13f831dec045cc82b744812b890ea7","IPY_MODEL_5ff1f8ce3a4b4f59a199d4286a6068bb","IPY_MODEL_1ff040bd4538419194fc1b47280fcffa"],"layout":"IPY_MODEL_fb6cbd268f7847599bffb0476e38f30c"}},"ea13f831dec045cc82b744812b890ea7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aca82f8dafdf494fa87bd5d6ff14e228","placeholder":"​","style":"IPY_MODEL_099364a9399c489195c99b544f38b961","value":"100%"}},"5ff1f8ce3a4b4f59a199d4286a6068bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef0149cd451046eca27c1dac396eb60c","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41b1217e2a074d72bf48142d7905a31b","value":30}},"1ff040bd4538419194fc1b47280fcffa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9125639ecbb4956993239c5fe722646","placeholder":"​","style":"IPY_MODEL_479bc2409dcc4b038d8a044fa7bd0881","value":" 30/30 [00:22&lt;00:00,  1.33it/s]"}},"fb6cbd268f7847599bffb0476e38f30c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aca82f8dafdf494fa87bd5d6ff14e228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"099364a9399c489195c99b544f38b961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef0149cd451046eca27c1dac396eb60c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b1217e2a074d72bf48142d7905a31b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9125639ecbb4956993239c5fe722646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"479bc2409dcc4b038d8a044fa7bd0881":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}